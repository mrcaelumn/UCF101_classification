{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdecc3-97b5-4ac6-b204-1400022582e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, \\\n",
    "auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from packaging import version\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "\"\"\" Set Hyper parameters \"\"\"\n",
    "MAX_SEQ_LENGTH = 100\n",
    "NUM_FEATURES = 2048\n",
    "IMG_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "IMG_CHANNELS = 3  ## Change this to 1 for grayscale.\n",
    "COLOUR_MODE = \"rgb\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# set dir of files\n",
    "TRAIN_DATASET_PATH = \"train.csv\"\n",
    "TEST_DATASET_PATH = \"test.csv\"\n",
    "ROOT_DATASET_PATH = \"dataset/UCF-101/\"\n",
    "SAVED_MODEL_PATH = \"saved_model/\"\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUGMENTATION = False\n",
    "TRAIN_MODE = True\n",
    "GENERATE_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19092e-f77b-47cd-a5a9-b7a19b179b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")\n",
    "\n",
    "center_crop_layer = tf.keras.layers.CenterCrop(IMG_SIZE, IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07881fc-4ef1-4ec9-b51b-e982421e15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(frame):\n",
    "    cropped = center_crop_layer(frame[None, ...])\n",
    "    cropped = cropped.numpy().squeeze()\n",
    "    return cropped\n",
    "\n",
    "# Following method is modified from this tutorial:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def load_video(path, max_frames=0):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center(frame)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def build_feature_extractor():\n",
    "    feature_extractor = tf.keras.applications.DenseNet121(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = tf.keras.applications.densenet.preprocess_input\n",
    "\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df32b5-b2e2-43ad-9d42-036cd9bf8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c123ece-f01d-416b-9247-06629ad5cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label preprocessing with StringLookup.\n",
    "label_processor = tf.keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]), mask_token=None\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1c274-e947-4adb-a099-aed9c9770f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    df['video_paths'] = df['tag'] + \"/\" + df['video_name']\n",
    "    video_paths = df[\"video_paths\"].values.tolist()\n",
    "    # video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    # print(labels)\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "    # print(video_paths)\n",
    "    # print(labels)\n",
    "    # `frame_features` are what we will feed to our sequence model.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :]\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "\n",
    "if GENERATE_DATASET:\n",
    "    train_data, train_labels= prepare_all_videos(train_df, ROOT_DATASET_PATH)\n",
    "    test_data, test_labels= prepare_all_videos(test_df, ROOT_DATASET_PATH)\n",
    "    \n",
    "#     np.save(\"train_data.npy\", train_data)\n",
    "#     np.save(\"train_labels.npy\", train_labels)\n",
    "    \n",
    "#     np.save(\"test_data.npy\", test_data)    \n",
    "#     np.save(\"test_labels.npy\", test_labels)\n",
    "\n",
    "# train_data, train_labels = np.load(\"train_data.npy\"), np.load(\"train_labels.npy\")\n",
    "# test_data, test_labels = np.load(\"test_data.npy\"), np.load(\"test_labels.npy\")\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb14e04-369b-47ff-957d-418ade750d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_our_model(nb_classes):\n",
    "    \n",
    "    frame_features_input = tf.keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = tf.keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.LSTM(200, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "\n",
    "    x = keras.layers.LSTM(200, return_sequences=True)(x)\n",
    "\n",
    "    x = keras.layers.GRU(20)(x)\n",
    "    #x = keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "    x = keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(nb_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = tf.keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d457f-8c7b-48e0-9c48-b394fc440a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    seq_model = build_our_model(len(class_vocab))\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        SAVED_MODEL_PATH, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.2,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "    )\n",
    "    seq_model.load_weights(SAVED_MODEL_PATH)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n",
    "\n",
    "_, sequence_model = run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
