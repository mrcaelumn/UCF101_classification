{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cdecc3-97b5-4ac6-b204-1400022582e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "from collections import deque\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, \\\n",
    "auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from packaging import version\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\"\n",
    "\n",
    "\"\"\" Set Hyper parameters \"\"\"\n",
    "MAX_SEQ_LENGTH = 100\n",
    "NUM_FEATURES = 2048\n",
    "IMG_SIZE = 224\n",
    "NUM_EPOCHS = 20\n",
    "IMG_CHANNELS = 3  ## Change this to 1 for grayscale.\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# set dir of files\n",
    "TRAIN_DATASET_PATH = \"train.csv\"\n",
    "TEST_DATASET_PATH = \"test.csv\"\n",
    "ROOT_DATASET_PATH = \"dataset/UCF-101/\"\n",
    "SAVED_MODEL_PATH = \"saved_model/\"\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "AUGMENTATION = False\n",
    "TRAIN_MODE = True\n",
    "GENERATE_DATASET = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19092e-f77b-47cd-a5a9-b7a19b179b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(f\"Total videos for training: {len(train_df)}\")\n",
    "print(f\"Total videos for testing: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07881fc-4ef1-4ec9-b51b-e982421e15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def crop_center_square(frame):\n",
    "#     y, x = frame.shape[0:2]\n",
    "#     min_dim = min(y, x)\n",
    "#     start_x = (x // 2) - (min_dim // 2)\n",
    "#     start_y = (y // 2) - (min_dim // 2)\n",
    "#     return frame[start_y : start_y+min_dim, start_x : start_x+min_dim]\n",
    "\n",
    "# Following method is modified from this tutorial:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def load_video(path, max_frames=20, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            # frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)\n",
    "\n",
    "def build_feature_extractor():\n",
    "    feature_extractor = tf.keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, IMG_CHANNELS),\n",
    "    )\n",
    "    preprocess_input = tf.keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = tf.keras.Input((IMG_SIZE, IMG_SIZE, IMG_CHANNELS))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return tf.keras.Model(inputs, outputs, name=\"feature_extractor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36df32b5-b2e2-43ad-9d42-036cd9bf8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c123ece-f01d-416b-9247-06629ad5cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label preprocessing with StringLookup.\n",
    "label_processor = tf.keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"tag\"]), mask_token=None\n",
    ")\n",
    "print(label_processor.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d1c274-e947-4adb-a099-aed9c9770f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    df['video_paths'] = root_dir + df['tag'] + \"/\" + df['video_name']\n",
    "    video_paths = df[\"video_paths\"].values.tolist()\n",
    "    # video_paths = df[\"video_name\"].values.tolist()\n",
    "    labels = df[\"tag\"].values\n",
    "    # print(labels)\n",
    "    labels = label_processor(labels[..., None]).numpy()\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx,path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.hike intern\n",
    "        #path = video_paths[idx]\n",
    "        frames = load_video(path)\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(shape=(1, MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "        temp_frame_featutes = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            try:\n",
    "                video_length = batch.shape[1]\n",
    "                length = min(MAX_SEQ_LENGTH, video_length)\n",
    "                for j in range(length):\n",
    "                    temp_frame_featutes[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "                temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "                frame_features[idx,] = temp_frame_featutes.squeeze()\n",
    "                frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "            except:\n",
    "                #print(i, j, length)\n",
    "                pass\n",
    "\n",
    "        gc.collect()\n",
    "        print(idx)\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "if GENERATE_DATASET:\n",
    "    train_data, train_labels= prepare_all_videos(train_df, ROOT_DATASET_PATH)\n",
    "    test_data, test_labels= prepare_all_videos(test_df, ROOT_DATASET_PATH)\n",
    "\n",
    "    with open('train_data.pkl','wb') as f:\n",
    "        pickle.dump(train_data, f)\n",
    "\n",
    "    with open('train_labels.pkl','wb') as f:\n",
    "        pickle.dump(train_labels, f)\n",
    "\n",
    "    with open('test_data.pkl','wb') as f:\n",
    "        pickle.dump(test_data, f)\n",
    "\n",
    "    with open('test_labels.pkl','wb') as f:\n",
    "        pickle.dump(test_labels, f)\n",
    "\n",
    "\n",
    "\n",
    "f = open('train_data.pkl', 'rb')\n",
    "train_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('train_labels.pkl', 'rb')\n",
    "train_labels = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('test_data.pkl', 'rb')\n",
    "test_data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "f = open('test_labels.pkl', 'rb')\n",
    "test_labels = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dc50b0-861b-4bf9-ae73-64d1df79dd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_result(epochs, loss, name, model_name, colour):\n",
    "    plt.plot(epochs, loss, colour, label=name)\n",
    "#     plt.plot(epochs, disc_loss, 'b', label='Discriminator loss')\n",
    "    plt.title(name)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(model_name+ '_'+name+'_epoch_result.png')\n",
    "    plt.show()\n",
    "    \n",
    "class CustomSaver(tf.keras.callbacks.Callback):\n",
    "    def __init__(self,\n",
    "                 model_path,\n",
    "                 n_model\n",
    "                ):\n",
    "        super(CustomSaver, self).__init__()\n",
    "        self.history = {}\n",
    "        self.epoch = []\n",
    "        self.model_path = model_path\n",
    "    \n",
    "        self.name_model = n_model\n",
    "        self.custom_loss = []\n",
    "        self.epochs_list = []\n",
    "            \n",
    "    def on_train_end(self, logs=None):\n",
    "        print(self.model_path)\n",
    "        self.model.save_weights(self.model_path)\n",
    "        \n",
    "        plot_epoch_result(self.epochs_list, self.custom_loss, \"Loss\", self.name_model, \"g\")\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is None:\n",
    "            logs = {}\n",
    "        self.epoch.append(epoch)\n",
    "        for k, v in logs.items():\n",
    "#             print(k, v)\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        self.epochs_list.append(epoch)\n",
    "        self.custom_loss.append(logs[\"loss\"])\n",
    "\n",
    "        if (epoch + 1) % 15 == 0:\n",
    "            self.model.save_weights(self.model_path)\n",
    "            print('saved for epoch',epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb14e04-369b-47ff-957d-418ade750d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_our_model(nb_classes):\n",
    "    \n",
    "    frame_features_input = tf.keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = tf.keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = tf.keras.layers.LSTM(200, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "\n",
    "    x = tf.keras.layers.LSTM(200, return_sequences=True)(x)\n",
    "\n",
    "    x = tf.keras.layers.GRU(20)(x)\n",
    "    #x = keras.layers.Dropout(0.4)(x)\n",
    "\n",
    "\n",
    "    x = tf.keras.layers.Dense(2048, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    \n",
    "    output = tf.keras.layers.Dense(nb_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    rnn_model = tf.keras.Model([frame_features_input, mask_input], output)\n",
    "\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d457f-8c7b-48e0-9c48-b394fc440a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    name_model = str(IMG_SIZE)+\"_UCF101_\"+str(NUM_EPOCHS)\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "    seq_model = build_our_model(len(class_vocab))\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        SAVED_MODEL_PATH, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "    \n",
    "    saver_callback = CustomSaver(\n",
    "            SAVED_MODEL_PATH,\n",
    "            name_model\n",
    "        )\n",
    "    \n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        # validation_split=0.2,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        callbacks=[checkpoint, saver_callback],\n",
    "    )\n",
    "    seq_model.load_weights(SAVED_MODEL_PATH)\n",
    "    \n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a8255-4e20-4698-9071-26d17cc49458",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"run experiments\")\n",
    "    _, sequence_model = run_experiment()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
